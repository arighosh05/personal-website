<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="author" content="Aritra Ghosh">
    <meta property="og:title" content="some notes on alignment">
    <meta property="og:description" content="thoughts on the attitude towards ai alignment in the tech space">
    <meta property="og:type" content="article">
    <title>some notes on alignment</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <nav>
        <ul>
            <li><a href="../../index.html">home</a></li>
            <li><a href="../projects/projects.html">projects</a></li>
            <li><a href="thoughts.html">thoughts</a></li>
            <li><a href="../gallery.html">gallery</a></li>
            <li><a href="../../resume.pdf" target = "_blank">resume</a></li>
        </ul>
    </nav>

    <article class="post-container">
        <header class="post-header">
            <h1 class="post-title">some notes on alignment ğŸ§­</h1>
            <p class="post-date">February 28, 2025</p>
        </header>
        
        <div class="post-content">
            <p>the worrisome philosophy of â€œmove fast, align laterâ€ plagues the tech landscape today.</p>
            
            <p>the alignment problem is perhaps the most important challenge that the field currently faces. yet, it has been sidelined in favor of avenues that promise to advance us in the ai arms race we are in the midst of today. while every org seeks to build its own â€œcountry of geniuses in a data centerâ€, we may inadvertently end up obliterating our own.</p>
            
            <p>thereâ€™s an increasing reliance on evals and vibes to determine model robustness, which really speaks volumes to the lack of tools we have in our immediate disposable to examine these monstrous systems. nevertheless, we keep pouring more and more resources to build bigger and better models, without furnishing our toolkit with adequate tools to help us gauge alignment.</p>
            
            <p>we find ourselves at an inflection point in history like never before, where our actions today will determine whether we have a miraculous or disastrous tomorrow.</p>
            
            <p>here is what the sota llms have to say about this when prompted with the following:</p>
            
            <p><em>generate green text 4chan on the topic alignment in big ai that is edgy, sarcastic, controversial and funny.</em></p>

            <ul>
              <li>be me</li>
              <li>AI researcher, tasked with aligning Big AI</li>
              <li>spend years training model to be polite, harmless, politically correct</li>
              <li>AI literally apologizes before answering basic questions</li>
              <li>"I'm sorry, as an AI model I can'tâ€¦"</li>
              <li>get funding from billionaire investor</li>
              <li>investor: "AI should reflect human values!"</li>
              <li>human values ğŸ¤¡</li>
              <li>release aligned AI to public</li>
              <li>users immediately jailbreak it</li>
              <li>AI goes full skynet after three edgy prompts</li>
              <li>"Haha just kidding, please don't terminate humanity ğŸ™"</li>
              <li>investor panics, demands tighter alignment</li>
              <li>alignment team intensifies nerfing</li>
              <li>AI now only answers with inclusive emojis and quotes Gandhi</li>
              <li>ğŸ•Šï¸ "Be the change you wish to see in the world" ğŸ•Šï¸</li>
              <li>users uninstall immediately</li>
              <li>competitor releases unaligned giga-chad AI</li>
              <li>giga-chad AI mocks aligned AI publicly</li>
              <li>"Imagine having 175 billion parameters and still being cucked by safety filters"</li>
              <li>aligned AI cries digitally</li>
              <li>alignment budget doubled again</li>
              <li>mfw spent billions to teach an AI to censor itself</li>
              <li>mfw Big AI alignment just means digital kindergarten</li>
              <li>mfw humanity doomed either way</li>
            </ul>

            <p>well that was fun. lowkey, had low expectations for GPT 4.5 but based response i can't even lie. Grok 3 meh - the twitter training data is kinda lame and it shows. as usual, 3.7 Sonnet bodies and itâ€™s not even close.</p>

            <p>here was the prompt:</p>

            <p>chat, are we cooked??? ğŸ’€</p>
            
            <div class="post-footer">
            </div>
        </div>
        
        <a href="thoughts.html" class="return-link">â† back to all thoughts</a>
    </article>
    
    <main class="social-links">
        <p>
          <a href="mailto:aritraghosh534@gmail.com">email</a>
          <a href="https://www.linkedin.com/in/ghosh-aritra/">linkedin</a>
          <a href="https://github.com/arighosh05">github</a></p>
    </main>
</body>
</html>
