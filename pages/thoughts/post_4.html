<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="author" content="Aritra Ghosh">
    <meta property="og:title" content="the case for ai maximalism">
    <meta property="og:description" content="thoughts on ai maximalism and the dangers of ai minimalism">
    <meta property="og:type" content="article">
    <title>the case for ai maximalism</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <nav>
        <ul>
            <li><a href="../../index.html">home</a></li>
            <li><a href="../projects/projects.html">projects</a></li>
            <li><a href="thoughts.html">thoughts</a></li>
            <li><a href="../gallery.html">gallery</a></li>
            <li><a href="../../resume.pdf" target = "_blank">resume</a></li>
        </ul>
    </nav>

    <article class="post-container">
        <header class="post-header">
            <h1 class="post-title">the case for ai maximalism ü§ñ</h1>
            <p class="post-date">March 23, 2025</p>
        </header>
        
        <div class="post-content">
            <p><a href="https://nav.al/pessimism" class="underlined-link">pessimism seems like an intellectually serious position</a>.</p>
            
            <p>let me be clear: my position is not one of driving progress in ai while turning a blind eye to its apparent risks. rather, my point is that a call to an end to scientific inquiry into the field is fundamentally misguided.</p>
            
            <p>and so, here i present a case for ai maximalism - that is, a case for maximizing our knowledge of these silicon-based tensor-multiplying systems.</p>
            
            <p>ai research is potentially dangerous. it poses serious existential threats to humanity. my argument is that this is a strong cause for ai maximalism. that because these systems can be prove to be very damaging to our society, it‚Äôs crucial that we chart the terrain of what‚Äôs out there in an open and trustworthy manner.</p>
          
            <ul>
              <li>the community around ai has been super receptive to the open-source community, as evidenced by the existence of open-source frameworks like PyTorch and LangChain, and orgs like DeepSeek and university-funded research labs that open-source their findings. </li>
              <li>top companies in the field regularly pump out research papers that greatly benefit the scientific community. furthermore, a lot of these companies are positioned to help humanity - the for-profit wing of OpenAI is controlled by its non-profit wing and Anthropic is registered as a public benefit corporation are some examples. </li>
              <li>despite free markets often pushing companies to adopt technical moats, the ai sector has not succumbed to that pressure, instead welcoming competition and sharing info to improve the frontier tech. the popularity of online leaderboards in this space - like llmarena and swe-bench - speak to this. in general, companies have been pushing for transparency within their work - DeepSeek publishing their seminal paper on reinforcement-learning for R1 and OpenAI integrating Model Cards are proof of this.</li>
            </ul>

            <p>all this to say, it‚Äôs arguably better to see incremental slow benefits in ai with appropriate overwatch from the scientific community than to see all research in the field be banned only for a curious cat in an underground lab somewhere to unknowingly stumble upon tech that they are incapable of containing. if anyone deserves to be in the frontline, it is companies and orgs that are required to be out in open, transparent in their endeavors, taxed on their profits, and held accountable by the public for the consequences of their actions.</p>

            <p>i know i have painted a quite a rosy picture of the current state of ai development. indeed, it may be argued that the there‚Äôs already sufficient cause for concern in today‚Äôs development climate, so much so that the ai minimalist argument i provided is rendered null and void. however, i believe there‚Äôs more progress to come, more knowledge to acquire. we‚Äôre in this together. perhaps its the naivete of youth, but i do genuinely think the only way out is through. </p>
            
            <div class="post-footer">
            </div>
        </div>
        
        <a href="thoughts.html" class="return-link">‚Üê back to all thoughts</a>
    </article>
    
    <main class="social-links">
        <p>
          <a href="mailto:aritraghosh534@gmail.com">email</a>
          <a href="https://www.linkedin.com/in/ghosh-aritra/">linkedin</a>
          <a href="https://github.com/arighosh05">github</a></p>
    </main>
</body>
</html>
