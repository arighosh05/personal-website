<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="author" content="Aritra Ghosh">
    <meta property="og:title" content="build a coding agent with me">
    <meta property="og:description" content="a code-along style blog on building a coding agent for code review">
    <meta property="og:type" content="article">
    <title>build a coding agent with me</title>
    <link rel="stylesheet" href="../../styles.css">
</head>
<body>
    <nav>
        <ul>
            <li><a href="../../index.html">home</a></li>
            <li><a href="projects.html">projects</a></li>
            <li><a href="../thoughts/thoughts.html">thoughts</a></li>
            <li><a href="../gallery.html">gallery</a></li>
            <li><a href="../../resume.pdf" target = "_blank">resume</a></li>
        </ul>
    </nav>

    <article class="post-container">
        <header class="post-header">
            <h1 class="post-title">build a coding agent with me üõ†Ô∏è</h1>
            <p class="post-date">March 4, 2025</p>
        </header>
        
        <div class="post-content">
            <p>put on the <em>Social Network</em> last night and got inspired so here we are.</p>

            <p>note : this blog is written in a code-along style. for a formal reference, check out the <a href="https://github.com/arighosh05/coding-agent/blob/main/README.md" class="underlined-link">README.md</a> in the project repository.</p>

            <p>the authoritative piece on building agents:</p>
            
            <p><a href="https://www.anthropic.com/engineering/building-effective-agents" class="underlined-link">https://www.anthropic.com/engineering/building-effective-agents</a></p>

            <div class="post-footer">
            </div>

            <p>phase 0 : planning</p>

            <p>planning is key, so it‚Äôs always a good idea to spend some time working out the details. the approach here is to iron out the higher-level details, slowly moving towards lower-level details, until we switch to implementation.</p>

            <p>to begin with, we need to pick a task for our agent. in our case, we‚Äôll build a coding agent to do code reviews for us. more specifically, we‚Äôd like our agent to take in as input some code and corresponding content and spit out as output a code review. we‚Äôd also like our agent to generate improved code based on the code review, if we so desire.</p>

            <p>in terms of the actual workflows we‚Äôd need to implement, considering that our task is neatly decomposed of two distinct tasks, i.e. generating code review and generating improved code. thus, it makes sense to break our workflow up into two separate workflows as well.</p>

            <p>for the first task, i.e. generating code review, we‚Äôd like to make sectioned llm calls in order to consider unique aspect of the code. the hope is that in doing so, we can uncover details that a single llm call may have missed. furthermore, we‚Äôd like the endow each llm call with two capabilities:</p>

            <ul>
              <li>tool calling: bunch of functions that the agent can call to perform static code analysis</li>
              <li>rag : bunch of documentation that the agent can refer in order to make contextualized analysis</li>
            </ul>

            <p>for the second task, i.e. generating improved code, we‚Äôd like to adopt a planner-executor workflow. the motivation behind doing so is that our planner will generate an action plan based on the input code and context, the generated code review, and any additional human input, after which, the executor will generate the code based on the action plan. for our purposed, we can stick to vanilla llm calls for this part.</p>

            <p>as hinted to previously, we‚Äôd also need to incorporate human-in-the-loop mechanisms. this makes sense because we‚Äôd the user to be able to provide feedback to the agent. </p>

            <p>great! now that we have touched base on the important bits, we can chalk up a blueprint for our agent. </p>

            <div style="text-align: center;">
              <img src="../../img/project_3_img1.png" alt="High Level Diagram" style="width:1000px; height:1000px;">
            </div>

            <p>now that we have our high level diagram, let‚Äôs move on to the next phase.</p>

            <div class="post-footer">
            </div>

            <p>phase 1: building</p>

            <p>the building process can take two forms: top-down or bottom-up. the former process refers to building the skeleton of the overall workflow first, and then incrementally fleshing it up. the latter process refers to working up to the higher-level details by implementing the lower-level details first.</p>

            <p>in our case, we‚Äôll follow a top-down process.</p>

            <ul>
              <li>to begin with, build out the skeleton of the first half of the agent. more concretely, this includes everything up to generating the code review. however, for now, we can skip the knowledge store and tool registry implementation and implement vanilla sectioned llm calls.</li>
              <li>next, extend the skeleton to incorporate the second half of the agent. this include the human-in-the-loop mechanisms and the planner-executor workflow.</li>
              <li>now‚Äôs a good time to take a break and run some preliminary tests on the agent, testing its robustness against different inputs.</li>
              <li>once satisfied, move to the contextual rag implementation. <a href = "https://www.anthropic.com/news/contextual-retrieval" class = "underlined-link">here‚Äôs</a> a good article on the topic.</li>
              <li>finally, add functions that perform static code analysis and make the results accessible to the agent.</li>
            </ul>          

            <div class="post-footer">
            </div>

            <p>phase 2: evals</p>

            <p>evals are meant to stress test your agent. unlike traditional code, agents are not easy to test, primarily due to the intrinsic non-deterministic nature of llms. as such, you should dedicate enough resources to comprehensively evaluate your agent against a plethora of scenarios. at the very least, run your agent with some common inputs you‚Äôd expect from users and ensure that your agent can handle unexpected input types. for inspiration, here‚Äôs the report i wrote up for the evals i ran against my agent.</p>

            <div class="post-footer">
            </div>

            <p>i wrote this blog after i built the agent, so while it may seem as though the the coding agent was built in a linear fashion, that could not further from the truth. building is fundamentally an iterative process. i‚Äôve compiled a list of <a href="https://github.com/arighosh05/coding-agent/blob/main/references.md" class="underlined-link">references</a> in my project repository that i believe serves as excellent further reading.</p>

            <p>until next time üëã</p>
        
            <div class="post-footer">
            </div>
          
        </div>
        
        <a href="projects.html" class="return-link">‚Üê back to all projects</a>
    </article>
    
    <main class="social-links">
        <p>
          <a href="mailto:aritraghosh534@gmail.com">email</a>
          <a href="https://www.linkedin.com/in/ghosh-aritra/">linkedin</a>
          <a href="https://github.com/arighosh05">github</a></p>
    </main>
</body>
</html>
